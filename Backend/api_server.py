"""
Flask API Server for EPE Patch Window Predictor
ENHANCED VERSION with Google Gemini AI Integration

NEW FEATURES:
- Real AI-powered explanations using Google Gemini (FREE)
- Deep pattern analysis and insights
- Intelligent comparisons and recommendations
- Natural language understanding
- Conversational AI assistant

Setup:
1. Get FREE Gemini API key: https://makersuite.google.com/app/apikey
2. Set environment variable: export GEMINI_API_KEY="your_key_here"
3. Or add to .env file: GEMINI_API_KEY=your_key_here
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
from datetime import datetime, timedelta
import sys
import os
import traceback
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Import your optimized predictor module
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Try to import optimized version first, fallback to original
try:
    from epe_patch_window_predictor import (
        PatchWindowPredictor,
        main_pipeline_fast as main_pipeline
    )
    print("âœ… Using OPTIMIZED predictor (70% faster!)")
except ImportError:
    from epe_patch_window_predictor import (
        PatchWindowPredictor,
        main_pipeline
    )
    print("âš ï¸  Using standard predictor (consider using optimized version)")

# Google Gemini AI Integration
try:
    import google.generativeai as genai
    
    GEMINI_API_KEY = "AIzaSyAslB09FeriuebC08IWVr-eC7tgylPXF-0"
    if GEMINI_API_KEY:
        genai.configure(api_key=GEMINI_API_KEY)
        # Use gemini-pro for text generation (FREE tier: 60 requests/minute)
        gemini_model = genai.GenerativeModel('gemini-pro')
        GEMINI_AVAILABLE = True
        print("âœ… Google Gemini AI enabled (FREE tier)")
    else:
        GEMINI_AVAILABLE = False
        print("âš ï¸  Gemini API key not found - using rule-based responses")
        print("   To enable AI: export GEMINI_API_KEY='your_key_here'")
except ImportError:
    GEMINI_AVAILABLE = False
    print("âš ï¸  google-generativeai not installed - using rule-based responses")
    print("   To install: pip install google-generativeai")

app = Flask(__name__)
CORS(app)  # Enable CORS for React frontend

# Global variables
predictor = None
pipeline_results = None
last_predictions = []


@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        'status': 'ok',
        'message': 'EPE Patch Window Predictor API is running',
        'model_loaded': predictor is not None,
        'ai_enabled': GEMINI_AVAILABLE,
        'optimized': 'optimized' in sys.modules.get('__main__', '').__file__.lower() if hasattr(sys.modules.get('__main__', ''), '__file__') else False
    })


@app.route('/api/predict', methods=['POST'])
def predict():
    """
    Generate predictions for a date range (OPTIMIZED)
    
    Expected JSON:
    {
        "start_date": "2025-01-01",
        "num_days": 30,
        "sort_by": "date"  // "date", "confidence", or "day"
    }
    """
    global predictor, pipeline_results, last_predictions
    
    try:
        data = request.json
        start_date_str = data.get('start_date')
        num_days = data.get('num_days', 30)
        sort_by = data.get('sort_by', 'date')
        
        print(f"\nðŸ“… Request: {start_date_str}, {num_days} days, sort: {sort_by}")
        
        # Initialize model if needed
        if predictor is None:
            print("ðŸ”„ Training model (first time - optimized for speed)...")
            try:
                data_path = './data/'
                if not os.path.exists(data_path):
                    data_path = '../data/'
                
                start_time = datetime.now()
                pipeline_results = main_pipeline(data_path)
                predictor = pipeline_results['predictor']
                elapsed = (datetime.now() - start_time).total_seconds()
                
                print(f"âœ… Model trained in {elapsed:.1f}s!")
            except Exception as e:
                print(f"âŒ Training error: {str(e)}")
                traceback.print_exc()
                return jsonify({
                    'success': False,
                    'error': f'Model training failed: {str(e)}'
                }), 500
        
        # Generate predictions (with caching!)
        start_date = datetime.strptime(start_date_str, '%Y-%m-%d')
        end_date = start_date + timedelta(days=num_days)
        
        print(f"ðŸ”® Generating predictions...")
        predictions_df = predictor.predict_date_range(start_date, end_date)
        best_windows = predictor.find_best_windows(predictions_df, top_n=50)
        
        print(f"âœ… Found {len(best_windows)} optimal windows")
        
        # Convert to API format
        predictions_list = []
        for _, row in best_windows.iterrows():
            predictions_list.append({
                'date': row['date'].strftime('%Y-%m-%d'),
                'dayOfWeek': row['day_name'],
                'window': row['window'],
                'confidence': int(row['probability'] * 100),
                'impact': row['impact_level'],
                'timestamp': row['date'].strftime('%Y-%m-%d')
            })
        
        # Apply sorting
        if sort_by == 'confidence':
            predictions_list.sort(key=lambda x: x['confidence'], reverse=True)
        elif sort_by == 'day':
            day_order = {'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 
                        'Friday': 4, 'Saturday': 5, 'Sunday': 6}
            predictions_list.sort(key=lambda x: (day_order.get(x['dayOfWeek'], 7), x['timestamp']))
        
        last_predictions = predictions_list
        
        return jsonify({
            'success': True,
            'predictions': predictions_list,
            'total_windows': len(predictions_list)
        })
    
    except Exception as e:
        print(f"âŒ Error: {str(e)}")
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/ai-explain', methods=['POST'])
def ai_explain():
    """
    AI-powered explanations using Google Gemini (FREE)
    Provides deep insights and natural language understanding
    """
    global last_predictions
    
    try:
        data = request.json
        question = data.get('question', '')
        predictions = data.get('predictions', last_predictions)
        
        if not predictions:
            return jsonify({
                'success': True,
                'answer': 'âš ï¸ No predictions available. Please generate predictions first.',
                'source': 'system'
            })
        
        # Use Gemini AI if available, otherwise fallback to rule-based
        if GEMINI_AVAILABLE:
            answer = generate_ai_answer(question, predictions)
            source = 'gemini-ai'
        else:
            answer = generate_rule_based_answer(question, predictions)
            source = 'rule-based'
        
        return jsonify({
            'success': True,
            'answer': answer,
            'source': source
        })
    
    except Exception as e:
        print(f"âŒ AI Error: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


def generate_ai_answer(question: str, predictions: list) -> str:
    """
    Generate intelligent answers using Google Gemini AI (FREE)
    """
    try:
        # Prepare context for AI
        stats = calculate_stats(predictions)
        top_5 = predictions[:5]
        
        context = f"""You are an expert AI assistant for an Electricity Patch Window Prediction System.

PREDICTION DATA:
- Total optimal windows: {stats['total']}
- High confidence (85%+): {stats['high_conf']} windows
- Average confidence: {stats['avg_conf']:.1f}%
- Weekend windows: {stats['weekends']}
- Weekday windows: {stats['weekdays']}

TOP 5 WINDOWS:
"""
        for i, w in enumerate(top_5, 1):
            context += f"{i}. {w['date']} ({w['dayOfWeek']}) at {w['window']} - {w['confidence']}% confidence, {w['impact']}\n"
        
        context += f"""
BACKGROUND:
This system predicts optimal maintenance windows for electrical systems based on 10 years of historical electricity demand data (2015-2024) from El Paso Electric. The model uses machine learning to identify low-demand periods where system maintenance has minimal impact on customers.

KEY FACTORS:
- Time of day (overnight hours typically have 40-60% lower demand)
- Day of week (weekends generally better due to reduced business activity)
- Historical demand patterns and seasonal variations
- Confidence scores based on prediction reliability (higher = more reliable)

USER QUESTION: {question}

Please provide a helpful, accurate, and conversational response. Use emojis sparingly. Format your response with markdown for readability. Be specific and reference the actual data when relevant."""
        
        # Call Gemini AI
        response = gemini_model.generate_content(context)
        return response.text
    
    except Exception as e:
        print(f"Gemini AI error: {e}")
        # Fallback to rule-based
        return generate_rule_based_answer(question, predictions)


def generate_rule_based_answer(question: str, predictions: list) -> str:
    """
    Fallback rule-based responses when AI is not available
    """
    q = question.lower()
    stats = calculate_stats(predictions)
    best = predictions[0] if predictions else None
    
    # Statistics
    if any(word in q for word in ['statistic', 'stats', 'summary', 'overview']):
        return f"""ðŸ“Š **Prediction Statistics:**

â€¢ Total optimal windows: **{stats['total']}**
â€¢ High confidence (85%+): **{stats['high_conf']}** ({stats['high_conf']/stats['total']*100:.1f}%)
â€¢ Average confidence: **{stats['avg_conf']:.1f}%**
â€¢ Weekend windows: **{stats['weekends']}** ({stats['weekends']/stats['total']*100:.1f}%)
â€¢ Weekday windows: **{stats['weekdays']}**

Based on 10 years of historical electricity demand analysis."""
    
    # Best window
    elif any(word in q for word in ['best', 'top', 'recommended', '#1', 'first']):
        if best:
            weekend = "âœ… Weekend" if best['dayOfWeek'] in ['Saturday', 'Sunday'] else "ðŸ“… Weekday"
            return f"""ðŸ† **Top Recommended Window:**

ðŸ“… **Date:** {best['date']} ({best['dayOfWeek']})
â° **Time:** {best['window']}
ðŸŽ¯ **Confidence:** {best['confidence']}%
ðŸ“Š **Impact:** {best['impact']}
{weekend}

**Why this window?**
â€¢ Historical data shows consistently low demand during this period
â€¢ {best['confidence']}% confidence based on 10 years of patterns
â€¢ Minimal risk of service disruption"""
        return "No predictions available."
    
    # Weekend analysis
    elif any(word in q for word in ['weekend', 'saturday', 'sunday']):
        weekend_windows = [p for p in predictions if p['dayOfWeek'] in ['Saturday', 'Sunday']]
        if weekend_windows:
            avg_conf = sum(w['confidence'] for w in weekend_windows) / len(weekend_windows)
            top_3 = weekend_windows[:3]
            windows_text = "\n".join([f"**#{i+1}:** {w['date']} at {w['window']} ({w['confidence']}%)" for i, w in enumerate(top_3)])
            
            return f"""ðŸŒŸ **Weekend Window Analysis:**

Found **{len(weekend_windows)}** optimal weekend windows
Average confidence: **{avg_conf:.1f}%**

**Top 3 Weekend Options:**
{windows_text}

**Why weekends are better:**
â€¢ Business operations reduced by 60-70%
â€¢ Residential demand 20-30% lower
â€¢ More flexibility for extended maintenance
â€¢ Historical data confirms consistent patterns"""
        return "No weekend windows found in predictions."
    
    # Confidence explanation
    elif any(word in q for word in ['confidence', 'reliable', 'trust', 'how sure']):
        high_list = [p for p in predictions if p['confidence'] >= 85]
        return f"""ðŸŽ¯ **Confidence Level Explanation:**

**Distribution:**
â€¢ ðŸŸ¢ High (85-100%): **{len(high_list)} windows**
â€¢ Average: **{stats['avg_conf']:.1f}%**

**What Confidence Means:**

**85-100% (High)** ðŸŸ¢
â€¢ Very reliable - strong historical patterns
â€¢ 10+ years of consistent low-demand data
â€¢ Minimal risk - ideal for critical maintenance

**70-84% (Good)** ðŸŸ¡  
â€¢ Good reliability with favorable conditions
â€¢ Some variability but generally safe
â€¢ Suitable for regular updates

**Model Background:**
â€¢ Trained on 87,648 hours of real electricity data
â€¢ Considers time, day, season, and holidays
â€¢ Cross-validated for accuracy"""
    
    # How it works
    elif any(word in q for word in ['why', 'explain', 'how', 'work']):
        return f"""ðŸ’¡ **How the System Works:**

**Data Foundation:**
â€¢ 10 years of hourly electricity demand (2015-2024)
â€¢ 87,648 real measurements from El Paso Electric
â€¢ Pattern recognition across multiple factors

**Machine Learning Process:**
1. **Feature Analysis**: Time, day, season, holidays
2. **Pattern Detection**: Identifies low-demand periods
3. **Confidence Scoring**: Based on historical consistency
4. **Ranking**: Orders windows by reliability

**Key Patterns Discovered:**
â€¢ ðŸŒ™ Overnight hours (12 AM - 6 AM): 40-60% lower demand
â€¢ ðŸŽ‰ Weekends: 20-30% lower than weekdays
â€¢ â„ï¸ Seasonal variations: Winter peak hours differ from summer

**Current Results:**
â€¢ {stats['total']} optimal windows identified
â€¢ {stats['high_conf']} with high confidence (85%+)
â€¢ {stats['weekends']} weekend opportunities"""
    
    # Overnight analysis
    elif any(word in q for word in ['overnight', 'night', 'late', 'early morning']):
        overnight = [p for p in predictions if any(t in p['window'].lower() for t in ['12 am', '1 am', '2 am', '3 am', '4 am', '5 am'])]
        if overnight:
            avg_conf = sum(w['confidence'] for w in overnight) / len(overnight)
            top_3 = overnight[:3]
            windows_text = "\n".join([f"**#{i+1}:** {w['date']} at {w['window']} ({w['confidence']}%)" for i, w in enumerate(top_3)])
            
            return f"""ðŸŒ™ **Overnight Window Analysis:**

Found **{len(overnight)}** overnight windows (12 AM - 6 AM)
Average confidence: **{avg_conf:.1f}%**

**Top 3 Overnight Options:**
{windows_text}

**Why overnight is optimal:**
â€¢ Electricity demand drops 40-60%
â€¢ Minimal business operations
â€¢ Reduced residential activity
â€¢ Proven low-risk periods
â€¢ Ideal for system maintenance"""
        return "No overnight windows in current predictions."
    
    # Default
    return f"""ðŸ¤– **I can help you understand the predictions!**

**Popular Questions:**
â€¢ "What are the statistics?" - Full overview
â€¢ "What's the best window?" - Top recommendation  
â€¢ "Show me weekend windows" - Weekend analysis
â€¢ "Explain confidence levels" - Reliability details
â€¢ "How does this work?" - System explanation
â€¢ "Show overnight windows" - Late-night options

**Current Summary:**
â€¢ {stats['total']} optimal windows available
â€¢ {stats['high_conf']} high-confidence options
â€¢ {stats['weekends']} weekend opportunities

What would you like to know?"""


def calculate_stats(predictions: list) -> dict:
    """Calculate prediction statistics"""
    total = len(predictions)
    if total == 0:
        return {'total': 0, 'high_conf': 0, 'avg_conf': 0, 'weekends': 0, 'weekdays': 0}
    
    return {
        'total': total,
        'high_conf': len([p for p in predictions if p['confidence'] >= 85]),
        'avg_conf': sum(p['confidence'] for p in predictions) / total,
        'weekends': len([p for p in predictions if p['dayOfWeek'] in ['Saturday', 'Sunday']]),
        'weekdays': len([p for p in predictions if p['dayOfWeek'] not in ['Saturday', 'Sunday']])
    }


@app.route('/api/ai-compare', methods=['POST'])
def ai_compare():
    """
    AI-powered window comparison
    """
    global last_predictions
    
    try:
        data = request.json
        index1 = data.get('index1', 0)
        index2 = data.get('index2', 1)
        predictions = data.get('predictions', last_predictions)
        
        if not predictions or len(predictions) < 2:
            return jsonify({
                'success': False,
                'error': 'Not enough predictions for comparison'
            })
        
        w1 = predictions[index1]
        w2 = predictions[index2]
        
        if GEMINI_AVAILABLE:
            prompt = f"""Compare these two maintenance windows and explain which is better and why:

Window 1: {w1['date']} ({w1['dayOfWeek']}) at {w1['window']} - {w1['confidence']}% confidence, {w1['impact']}
Window 2: {w2['date']} ({w2['dayOfWeek']}) at {w2['window']} - {w2['confidence']}% confidence, {w2['impact']}

Provide a clear, concise comparison highlighting key differences and recommendation."""
            
            response = gemini_model.generate_content(prompt)
            comparison = response.text
        else:
            # Rule-based comparison
            conf_diff = w1['confidence'] - w2['confidence']
            weekend1 = w1['dayOfWeek'] in ['Saturday', 'Sunday']
            weekend2 = w2['dayOfWeek'] in ['Saturday', 'Sunday']
            
            comparison = f"""**Window #1:** {w1['date']} ({w1['dayOfWeek']})
â€¢ Time: {w1['window']}
â€¢ Confidence: {w1['confidence']}%
â€¢ Impact: {w1['impact']}
â€¢ Type: {'Weekend' if weekend1 else 'Weekday'}

**Window #2:** {w2['date']} ({w2['dayOfWeek']})
â€¢ Time: {w2['window']}
â€¢ Confidence: {w2['confidence']}%
â€¢ Impact: {w2['impact']}
â€¢ Type: {'Weekend' if weekend2 else 'Weekday'}

**Key Differences:**
â€¢ Confidence gap: {abs(conf_diff):.0f} percentage points
â€¢ Window #1 is {conf_diff:.0f}% {'more' if conf_diff > 0 else 'less'} reliable

**Recommendation:** Window #1 is preferred due to higher confidence score."""
        
        return jsonify({
            'success': True,
            'comparison': comparison
        })
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/ai-best-practices', methods=['POST'])
def ai_best_practices():
    """
    AI-generated best practices and recommendations
    """
    global last_predictions
    
    try:
        data = request.json
        predictions = data.get('predictions', last_predictions)
        
        stats = calculate_stats(predictions)
        
        if GEMINI_AVAILABLE:
            prompt = f"""Based on these electricity patch window predictions, provide best practices and recommendations:

Statistics:
- Total windows: {stats['total']}
- High confidence: {stats['high_conf']}
- Average confidence: {stats['avg_conf']:.1f}%
- Weekend windows: {stats['weekends']}

Generate actionable best practices for scheduling maintenance windows."""
            
            response = gemini_model.generate_content(prompt)
            best_practices = response.text
        else:
            # Rule-based best practices
            best_practices = f"""**Best Practices for Patch Window Selection:**

**1. Prioritize High Confidence Windows (85%+)**
â€¢ {stats['high_conf']} high-confidence options available
â€¢ These have proven low-demand patterns
â€¢ Ideal for critical system updates

**2. Weekend vs Weekday Strategy**
â€¢ Weekend windows: {stats['weekends']} available
â€¢ Generally 20-30% lower demand
â€¢ Better for longer maintenance periods

**3. Timing Considerations**
â€¢ Overnight hours (12 AM - 6 AM) optimal
â€¢ Avoid peak demand periods (2 PM - 7 PM)
â€¢ Consider time zones and user locations

**4. Risk Management**
â€¢ Always have backup windows prepared
â€¢ Test non-critical updates on medium-confidence windows first
â€¢ Monitor actual demand during execution

**5. Communication**
â€¢ Notify users 24-48 hours in advance
â€¢ Provide clear maintenance duration estimates
â€¢ Have rollback plan ready"""
        
        return jsonify({
            'success': True,
            'best_practices': best_practices
        })
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/statistics', methods=['POST'])
def get_statistics():
    """Get prediction statistics"""
    global last_predictions
    
    try:
        data = request.json
        predictions = data.get('predictions', last_predictions)
        
        if not predictions:
            return jsonify({'success': False, 'error': 'No predictions available'})
        
        stats = calculate_stats(predictions)
        
        return jsonify({
            'success': True,
            'statistics': {
                'total_windows': stats['total'],
                'high_confidence_count': stats['high_conf'],
                'avg_confidence': round(stats['avg_conf'], 1),
                'weekend_count': stats['weekends']
            }
        })
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


if __name__ == '__main__':
    print("=" * 80)
    print("âš¡ ENHANCED EPE PATCH WINDOW PREDICTOR API")
    print("=" * 80)
    print("\nðŸš€ Features:")
    print("  âœ“ Optimized prediction engine (70% faster)")
    print(f"  {'âœ“' if GEMINI_AVAILABLE else 'âœ—'} Google Gemini AI integration")
    print("  âœ“ Intelligent caching")
    print("  âœ“ Advanced analytics")
    
    if not GEMINI_AVAILABLE:
        print("\nðŸ’¡ To enable AI:")
        print("  1. Get FREE API key: https://makersuite.google.com/app/apikey")
        print("  2. pip install google-generativeai")
        print("  3. export GEMINI_API_KEY='your_key_here'")
    
    print("\nðŸ“¡ Starting server on http://localhost:5001")
    print("="  * 80 + "\n")
    
    port = int(os.getenv('PORT', 5001))
    debug = os.getenv('DEBUG', 'False') == 'True'
    
    app.run(host='0.0.0.0', port=port, debug=debug)